#!/usr/bin/env python3
"""
Markdown è½‰æ›å™¨
å°‡åŸºæ–¼è¡Œçš„åˆ†å¡Šçµæœè½‰æ›ç‚º Markdown æ ¼å¼

è½‰æ›è¦å‰‡ï¼š
- Level 1, 2, 3, 4, 5, 6... â†’ æ•¸å­—åˆ—è¡¨ (1., 2., 3...)
- Level 0 â†’ H2 æ¨™é¡Œ (##)
- Level -1 â†’ ç´”æ–‡å­—
- Level -2 â†’ å¿½ç•¥ (é€šå¸¸æ˜¯æ—¥æœŸ)
- Level -3 â†’ å¿½ç•¥ (é€šå¸¸æ˜¯ header/footer)
"""

from typing import List, Dict, Optional
from dataclasses import dataclass
from ..detectors.adaptive_hybrid import LineBasedChunk, IntelligentDetectionResult

@dataclass
class MarkdownSection:
    """Markdown ç« ç¯€"""
    level: int
    content: str
    section_type: str  # "heading", "numbered_list", "plain_text"
    
class MarkdownConverter:
    """Markdown è½‰æ›å™¨"""
    
    def __init__(self):
        self.conversion_stats = {}
    
    def convert_chunks_to_markdown(self, chunks: List[LineBasedChunk], 
                                 include_metadata: bool = False) -> str:
        """
        å°‡åˆ†å¡Šçµæœè½‰æ›ç‚º Markdown æ ¼å¼
        
        Args:
            chunks: åŸºæ–¼è¡Œçš„åˆ†å¡Šçµæœ
            include_metadata: æ˜¯å¦åŒ…å«å…ƒæ•¸æ“šè¨»é‡‹
            
        Returns:
            Markdown æ ¼å¼çš„æ–‡æœ¬
        """
        markdown_lines = []
        self.conversion_stats = {'h2_count': 0, 'numbered_list_count': 0, 'plain_text_count': 0}
        
        if include_metadata:
            markdown_lines.append("<!-- Generated by L-chunk md_converter -->")
            markdown_lines.append("")
        
        # æŒ‰ level åˆ†çµ„èšåˆå…§å®¹
        level_groups = self._group_chunks_by_level(chunks)
        
        # æŒ‰ level é †åºè™•ç†ï¼ˆè² æ•¸åœ¨å‰ï¼Œ0åœ¨ä¸­é–“ï¼Œæ­£æ•¸åœ¨å¾Œï¼‰
        sorted_levels = sorted(level_groups.keys())
        
        for level in sorted_levels:
            chunk_group = level_groups[level]
            
            # å¿½ç•¥ Level -2 (æ—¥æœŸ) å’Œ Level -3 (header/footer)
            if level in [-2, -3]:
                continue
            
            markdown_section = self._convert_level_to_markdown(level, chunk_group)
            if markdown_section:
                markdown_lines.extend(markdown_section)
                markdown_lines.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”
        
        # ç§»é™¤æœ€å¾Œçš„ç©ºè¡Œ
        while markdown_lines and markdown_lines[-1] == "":
            markdown_lines.pop()
        
        if include_metadata:
            markdown_lines.append("")
            markdown_lines.append(f"<!-- Conversion Stats: {self.conversion_stats} -->")
        
        return "\n".join(markdown_lines)
    
    def _group_chunks_by_level(self, chunks: List[LineBasedChunk]) -> Dict[int, List[LineBasedChunk]]:
        """æŒ‰å±¤ç´šåˆ†çµ„åˆ†å¡Š"""
        level_groups = {}
        
        for chunk in chunks:
            level = chunk.level
            if level not in level_groups:
                level_groups[level] = []
            level_groups[level].append(chunk)
        
        return level_groups
    
    def _convert_level_to_markdown(self, level: int, chunks: List[LineBasedChunk]) -> List[str]:
        """å°‡ç‰¹å®šå±¤ç´šçš„åˆ†å¡Šè½‰æ›ç‚º Markdown"""
        markdown_lines = []
        
        # åˆä½µåŒå±¤ç´šçš„å…§å®¹
        merged_content = self._merge_chunk_content(chunks)
        
        if not merged_content.strip():
            return []
        
        if level == 0:
            # Level 0 â†’ H2 æ¨™é¡Œ
            markdown_lines.append(f"## {merged_content.strip()}")
            self.conversion_stats['h2_count'] += 1
            
        elif level >= 1:
            # Level 1, 2, 3, 4... â†’ æ•¸å­—åˆ—è¡¨
            indent = "  " * (level - 1)  # æ¯å±¤ç´šç¸®æ’ 2 å€‹ç©ºæ ¼
            list_number = 1
            
            for line in merged_content.strip().split('\n'):
                line = line.strip()
                if line:
                    markdown_lines.append(f"{indent}{list_number}. {line}")
                    list_number += 1
            
            self.conversion_stats['numbered_list_count'] += len([l for l in merged_content.strip().split('\n') if l.strip()])
            
        elif level == -1:
            # Level -1 â†’ ç´”æ–‡å­—
            for line in merged_content.strip().split('\n'):
                line = line.strip()
                if line:
                    markdown_lines.append(line)
            
            self.conversion_stats['plain_text_count'] += len([l for l in merged_content.strip().split('\n') if l.strip()])
        
        return markdown_lines
    
    def _merge_chunk_content(self, chunks: List[LineBasedChunk]) -> str:
        """åˆä½µåˆ†å¡Šå…§å®¹"""
        all_content = []
        
        for chunk in chunks:
            # è·³éç©ºå…§å®¹
            if not chunk.content_lines:
                continue
            
            # åˆä½µå…§å®¹è¡Œ
            for line in chunk.content_lines:
                line_text = line.strip()
                if line_text:
                    all_content.append(line_text)
        
        return "\n".join(all_content)
    
    def convert_detection_result_to_markdown(self, detection_result: IntelligentDetectionResult,
                                           include_metadata: bool = True) -> str:
        """
        å°‡å®Œæ•´çš„æª¢æ¸¬çµæœè½‰æ›ç‚º Markdown
        
        Args:
            detection_result: æ™ºèƒ½æª¢æ¸¬çµæœ
            include_metadata: æ˜¯å¦åŒ…å«å…ƒæ•¸æ“š
            
        Returns:
            Markdown æ ¼å¼çš„æ–‡æœ¬
        """
        if not detection_result.line_based_chunks:
            return "<!-- No line-based chunks available for conversion -->"
        
        markdown_content = self.convert_chunks_to_markdown(
            detection_result.line_based_chunks, 
            include_metadata=include_metadata
        )
        
        if include_metadata:
            # æ·»åŠ æª”æ¡ˆè³‡è¨Š
            metadata_header = [
                f"<!-- File: {detection_result.filename} -->",
                f"<!-- Learning Region: {detection_result.learning_region} -->",
                f"<!-- Total Chunks: {len(detection_result.line_based_chunks)} -->",
                "",
                markdown_content
            ]
            return "\n".join(metadata_header)
        
        return markdown_content
    
    def batch_convert_to_markdown(self, detection_results: List[IntelligentDetectionResult],
                                output_dir: Optional[str] = None) -> Dict[str, str]:
        """
        æ‰¹é‡è½‰æ›å¤šå€‹æª¢æ¸¬çµæœç‚º Markdown
        
        Args:
            detection_results: å¤šå€‹æª¢æ¸¬çµæœ
            output_dir: è¼¸å‡ºç›®éŒ„ï¼ˆå¯é¸ï¼‰
            
        Returns:
            æª”æ¡ˆå â†’ Markdown å…§å®¹çš„å­—å…¸
        """
        converted_files = {}
        
        for result in detection_results:
            if not result.line_based_chunks:
                continue
            
            markdown_content = self.convert_detection_result_to_markdown(result)
            
            # ç”Ÿæˆè¼¸å‡ºæª”å
            base_name = result.filename.replace('.json', '')
            markdown_filename = f"{base_name}_converted.md"
            
            converted_files[markdown_filename] = markdown_content
            
            # å¦‚æœæŒ‡å®šè¼¸å‡ºç›®éŒ„ï¼Œå‰‡å¯«å…¥æª”æ¡ˆ
            if output_dir:
                from pathlib import Path
                output_path = Path(output_dir)
                output_path.mkdir(parents=True, exist_ok=True)
                
                output_file = output_path / markdown_filename
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(markdown_content)
                
                print(f"âœ… å·²è¼¸å‡º: {output_file}")
        
        return converted_files

# ä½¿ç”¨ç¯„ä¾‹
def demo_md_converter():
    """æ¼”ç¤º Markdown è½‰æ›å™¨çš„ä½¿ç”¨"""
    from ..detectors.adaptive_hybrid import LineBasedChunk
    
    # å»ºç«‹æ¸¬è©¦åˆ†å¡Š
    test_chunks = [
        LineBasedChunk(
            level=-3, start_line=0, end_line=2, chunk_type="header",
            content_lines=["æ³•é™¢é ­éƒ¨", "æ¡ˆä»¶ç·¨è™Ÿ", "ç•¶äº‹äººè³‡è¨Š"]
        ),
        LineBasedChunk(
            level=0, start_line=5, end_line=5, chunk_type="main_text",
            content_lines=["ä¸»æ–‡"]
        ),
        LineBasedChunk(
            level=-1, start_line=6, end_line=8, chunk_type="content",
            content_lines=["åŸå‘Šå‹è¨´", "è¢«å‘Šæ‡‰çµ¦ä»˜æ–°å°å¹£ä¸€ç™¾è¬å…ƒ", "è¨´è¨Ÿè²»ç”¨ç”±è¢«å‘Šè² æ“”"]
        ),
        LineBasedChunk(
            level=0, start_line=10, end_line=10, chunk_type="facts",
            content_lines=["äº‹å¯¦"]
        ),
        LineBasedChunk(
            level=1, start_line=11, end_line=12, chunk_type="leveling_symbol",
            content_lines=["ä¸€ã€ç•¶äº‹äººèƒŒæ™¯", "äºŒã€çˆ­è­°äº‹é …"], leveling_symbol="ä¸€ã€"
        ),
        LineBasedChunk(
            level=2, start_line=13, end_line=14, chunk_type="leveling_symbol", 
            content_lines=["ï¼ˆä¸€ï¼‰å¥‘ç´„ç°½è¨‚ç¶“é", "ï¼ˆäºŒï¼‰å±¥è¡Œç‹€æ³"], leveling_symbol="ï¼ˆä¸€ï¼‰"
        ),
        LineBasedChunk(
            level=-2, start_line=20, end_line=20, chunk_type="dates",
            content_lines=["ä¸­è¯æ°‘åœ‹113å¹´10æœˆ14æ—¥"]
        )
    ]
    
    # è½‰æ›ç‚º Markdown
    converter = MarkdownConverter()
    markdown_result = converter.convert_chunks_to_markdown(test_chunks, include_metadata=True)
    
    print("ğŸ“ Markdown è½‰æ›çµæœ:")
    print("=" * 50)
    print(markdown_result)
    print("=" * 50)
    print(f"è½‰æ›çµ±è¨ˆ: {converter.conversion_stats}")

if __name__ == "__main__":
    demo_md_converter()