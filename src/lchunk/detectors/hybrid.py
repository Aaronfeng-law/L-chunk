#!/usr/bin/env python3
"""
ä¸‰å±¤æ··åˆå±¤ç´šç¬¦è™Ÿæª¢æ¸¬å™¨ (æ¨ç†å°ˆç”¨)
"åˆ†å±¤éæ¿¾" åŸå‰‡ï¼šåš´æ ¼ â†’ è»Ÿè¦å‰‡ â†’ èšåˆ

ä¸‰å±¤ç­–ç•¥ï¼š
1. çµ‚æ¥µåš´æ ¼è¦å‰‡ï¼šPUAå­—ç¬¦ + é “è™Ÿ = 100% ç¢ºå®š
2. è»Ÿè¦å‰‡ + BERTï¼šå…¶ä»–ç¬¦è™Ÿéœ€è¦èªç¾©é©—è­‰
3. æœ€çµ‚èšåˆï¼šåˆä½µæ‰€æœ‰æª¢æ¸¬çµæœ

æ³¨æ„ï¼šæ­¤ç‰ˆæœ¬åªè² è²¬æ¨ç†ï¼Œä¸åŒ…å«è¨“ç·´åŠŸèƒ½
è¨“ç·´è«‹ä½¿ç”¨ train_bert_classifier.py
"""

import json
import numpy as np
import torch
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# å°å…¥ç¾æœ‰æª¢æ¸¬å™¨
from .ultra_strict import UltraStrictDetector

# BERTç›¸é—œ
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch.nn.functional as F
import numpy as np

def convert_numpy_types(obj):
    """è½‰æ› numpy é¡å‹ç‚º Python åŸç”Ÿé¡å‹ - """
    if isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, (np.integer, np.floating)):
        return float(obj)
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    return obj

@dataclass
class HybridDetectionResult:
    """æ··åˆæª¢æ¸¬çµæœ"""
    line_number: int
    line_text: str
    detected_symbol: str
    symbol_category: str
    rule_based_score: float  # è¦å‰‡æª¢æ¸¬ä¿¡å¿ƒåº¦ (0, 0.5, 1.0)
    bert_score: float        # BERTåˆ†é¡ä¿¡å¿ƒåº¦ (0-1)
    final_prediction: bool   # æœ€çµ‚é æ¸¬çµæœ
    method_used: str         # ä½¿ç”¨çš„æ–¹æ³• ("ultra_strict_pua", "soft_rule_bert", "rule_rejected", etc.)

class HybridLevelSymbolDetector:
    """ä¸‰å±¤æ··åˆå±¤ç´šç¬¦è™Ÿæª¢æ¸¬å™¨ (æ¨ç†å°ˆç”¨)"""
    
    def __init__(self, model_path: Optional[str] = None):
        # åˆå§‹åŒ–è¦å‰‡æª¢æ¸¬å™¨
        self.rule_detector = UltraStrictDetector()
        
        # BERT æ¨¡å‹ç›¸é—œ
        self.bert_model = None
        self.bert_tokenizer = None
        self.model_path = model_path
        
        # æª¢æ¸¬çµæœ
        self.detection_results = []
        
        # å¦‚æœæä¾›äº†æ¨¡å‹è·¯å¾‘ä¸”è·¯å¾‘å­˜åœ¨ï¼Œç›´æ¥è¼‰å…¥
        if model_path is not None and Path(model_path).exists():
            self.load_bert_model(model_path)
    
    def load_bert_model(self, model_path: Optional[str] = None):
        """è¼‰å…¥è¨“ç·´å¥½çš„ BERT æ¨¡å‹"""
        if model_path:
            self.model_path = Path(model_path)
        elif self.model_path:
            self.model_path = Path(self.model_path)
        else:
            raise ValueError("è«‹æä¾›æ¨¡å‹è·¯å¾‘")
        
        if not self.model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹è·¯å¾‘ä¸å­˜åœ¨: {self.model_path}")
        
        print(f"ğŸ“¦ è¼‰å…¥ BERT æ¨¡å‹: {self.model_path}")
        
        self.bert_tokenizer = AutoTokenizer.from_pretrained(self.model_path)
        self.bert_model = AutoModelForSequenceClassification.from_pretrained(self.model_path)
        
        # è‡ªé©æ‡‰è¨­å‚™é¸æ“‡ - å„ªå…ˆä½¿ç”¨ GPU
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.bert_model = self.bert_model.to(device)
        self.bert_model.eval()
        
        print(f"âœ… BERT æ¨¡å‹è¼‰å…¥å®Œæˆ (device: {device})")
    
    def is_model_loaded(self) -> bool:
        """æª¢æŸ¥ BERT æ¨¡å‹æ˜¯å¦å·²è¼‰å…¥"""
        return self.bert_model is not None and self.bert_tokenizer is not None
    
    def _is_ultra_strict_pua_symbol(self, line_text: str) -> Tuple[bool, str, str]:
        """æª¢æŸ¥æ˜¯å¦ç‚ºçµ‚æ¥µåš´æ ¼çš„ PUA ç¬¦è™Ÿï¼šPUAå­—ç¬¦ + é “è™Ÿ"""
        if not line_text or len(line_text.strip()) < 2:
            return False, None, None
        
        clean_text = line_text.strip()
        first_char = clean_text[0]
        
        # æª¢æŸ¥æ˜¯å¦ç‚º PUA å­—ç¬¦
        if not self.rule_detector.is_pua_character(first_char):
            return False, None, None
        
        # æª¢æŸ¥æ˜¯å¦ç·Šè·Ÿé “è™Ÿ
        if len(clean_text) > 1 and clean_text[1] == 'ã€':
            # ç¢ºå®š PUA åˆ†çµ„
            pua_group = self.rule_detector.get_pua_group(first_char)
            return True, first_char, pua_group or "PUA_æœªåˆ†é¡"
        
        return False, None, None
    
    def _get_line_symbol_info(self, line_text: str) -> Tuple[bool, str, str]:
        """æª¢æŸ¥è¡Œæ˜¯å¦ä»¥å±¤ç´šç¬¦è™Ÿé–‹é ­ï¼ˆè»Ÿè¦å‰‡ï¼‰"""
        if not line_text or len(line_text.strip()) == 0:
            return False, None, None
        
        first_char = line_text.strip()[0]
        
        # æª¢æŸ¥æ˜¯å¦åœ¨é å®šç¾©çš„ç¬¦è™Ÿç¯„åœå…§
        for category, info in self.rule_detector.valid_symbol_ranges.items():
            if first_char in info["chars"]:
                return True, first_char, category
        
        # æª¢æŸ¥PUAç¬¦è™Ÿï¼ˆä½†ä¸è¦æ±‚é “è™Ÿï¼‰
        for pua_category, pua_info in self.rule_detector.pua_symbol_groups.items():
            if 'chars' in pua_info and first_char in pua_info['chars']:
                return True, first_char, pua_category
        
        return False, None, None
    
    def bert_classify_lines(self, lines: List[str], batch_size: int = 32) -> List[Tuple[float, int]]:
        """ä½¿ç”¨ BERT å°è¡Œé€²è¡Œåˆ†é¡ - å„ªåŒ– GPU æ¨ç†æ€§èƒ½ï¼Œæ”¯æŒåˆ†æ‰¹è™•ç†é¿å… OOM"""
        if not self.is_model_loaded():
            raise ValueError("è«‹å…ˆè¼‰å…¥ BERT æ¨¡å‹")
        
        if not lines:
            return []
        
        try:
            # è‡ªé©æ‡‰è¨­å‚™é¸æ“‡
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            self.bert_model = self.bert_model.to(device)
            
            all_results = []
            
            # åˆ†æ‰¹è™•ç†ä»¥é¿å… OOM
            for batch_start in range(0, len(lines), batch_size):
                batch_end = min(batch_start + batch_size, len(lines))
                batch_lines = lines[batch_start:batch_end]
                
                # æº–å‚™è¼¸å…¥
                inputs = self.bert_tokenizer(
                    batch_lines,
                    truncation=True,
                    padding=True,
                    max_length=512,
                    return_tensors="pt"
                )
                
                # å°‡è¼¸å…¥ç§»åˆ°åŒä¸€è¨­å‚™
                inputs = {k: v.to(device) for k, v in inputs.items()}
                
                # é æ¸¬
                with torch.no_grad():
                    outputs = self.bert_model(**inputs)
                    probabilities = F.softmax(outputs.logits, dim=1)
                    predictions = torch.argmax(probabilities, dim=1)
                    scores = probabilities[:, 1]  # æ­£é¡åˆ¥çš„æ¦‚ç‡
                
                # è¿”å›çµæœåˆ° CPU ä¸¦ä¿å­˜
                batch_results = list(zip(scores.cpu().numpy(), predictions.cpu().numpy()))
                all_results.extend(batch_results)
                
                # æ¸…ç†ä¸­é–“å¼µé‡
                del inputs, outputs, probabilities, predictions, scores
                
                # åœ¨æ¯å€‹æ‰¹æ¬¡å¾Œæ¸…ç† CUDA å¿«å–
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            
            return all_results
        
        finally:
            # æœ€çµ‚æ¸…ç† CUDA å¿«å–
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
    
    def detect_hybrid_markers(self, text_lines: List[str], bert_threshold: float = 0.5, verbose: bool = True) -> List[HybridDetectionResult]:
        """ä¸‰å±¤æ··åˆæª¢æ¸¬å±¤ç´šæ¨™è¨˜ - """
        if verbose:
            print("ğŸ” å•Ÿå‹•ä¸‰å±¤æ··åˆæª¢æ¸¬...")
        
        results = []
        ultra_strict_results = []
        soft_candidate_lines = []
        soft_line_mapping = {}
        
        # ç¬¬ä¸€å±¤ï¼šçµ‚æ¥µåš´æ ¼è¦å‰‡ (PUA + é “è™Ÿ) - 100% ç¢ºå®š
        if verbose:
            print("ğŸ¯ æ­¥é©Ÿ1: çµ‚æ¥µåš´æ ¼è¦å‰‡ (PUA + é “è™Ÿ)")
        
        for line_num, line_text in enumerate(text_lines, 1):
            clean_text = line_text.strip()
            if not clean_text:
                # ç©ºè¡Œè¨˜éŒ„ç‚ºè² é¡
                results.append(HybridDetectionResult(
                    line_number=line_num,
                    line_text=clean_text,
                    detected_symbol=None,
                    symbol_category=None,
                    rule_based_score=0.0,
                    bert_score=0.0,
                    final_prediction=False,
                    method_used="empty_line"
                ))
                continue
            
            # æª¢æŸ¥çµ‚æ¥µåš´æ ¼è¦å‰‡
            is_ultra_strict, detected_symbol, symbol_category = self._is_ultra_strict_pua_symbol(clean_text)
            
            if is_ultra_strict:
                # PUA + é “è™Ÿ = 100% ç¢ºå®šçš„å±¤ç´šç¬¦è™Ÿ
                ultra_strict_results.append(HybridDetectionResult(
                    line_number=line_num,
                    line_text=clean_text,
                    detected_symbol=detected_symbol,
                    symbol_category=symbol_category,
                    rule_based_score=1.0,
                    bert_score=1.0,  # 100% ä¿¡å¿ƒ
                    final_prediction=True,
                    method_used="ultra_strict_pua"
                ))
            else:
                # æª¢æŸ¥è»Ÿè¦å‰‡ (å…¶ä»–ç¬¦è™Ÿé–‹é ­)
                is_symbol_line, soft_symbol, soft_category = self._get_line_symbol_info(clean_text)
                
                if is_symbol_line:
                    # è»Ÿè¦å‰‡å€™é¸ï¼Œéœ€è¦ BERT é©—è­‰
                    soft_candidate_lines.append(clean_text)
                    soft_line_mapping[len(soft_candidate_lines) - 1] = {
                        'line_number': line_num,
                        'line_text': clean_text,
                        'detected_symbol': soft_symbol,
                        'symbol_category': soft_category
                    }
                else:
                    # éå€™é¸è¡Œè¨˜éŒ„ç‚ºè² é¡
                    results.append(HybridDetectionResult(
                        line_number=line_num,
                        line_text=clean_text,
                        detected_symbol=None,
                        symbol_category=None,
                        rule_based_score=0.0,
                        bert_score=0.0,
                        final_prediction=False,
                        method_used="rule_rejected"
                    ))
        
        if verbose:
            print(f"âœ… çµ‚æ¥µåš´æ ¼è¦å‰‡ç¢ºå®š {len(ultra_strict_results)} å€‹å±¤ç´šç¬¦è™Ÿ")
            print(f"ğŸ“‹ è»Ÿè¦å‰‡æ‰¾åˆ° {len(soft_candidate_lines)} å€‹å€™é¸è¡Œ")
        
        # ç¬¬äºŒå±¤ï¼šè»Ÿè¦å‰‡ + BERT åˆ†é¡
        if soft_candidate_lines and self.is_model_loaded():
            if verbose:
                print("ğŸ¤– æ­¥é©Ÿ2: BERT ç²¾ç´°åˆ†é¡è»Ÿè¦å‰‡å€™é¸...")
            bert_results = self.bert_classify_lines(soft_candidate_lines)
            
            for i, (bert_score, bert_prediction) in enumerate(bert_results):
                line_info = soft_line_mapping[i]
                
                # åŸºæ–¼ BERT é–¾å€¼æ±ºå®šæœ€çµ‚çµæœ
                final_prediction = bert_score >= bert_threshold
                method_used = "soft_rule_bert"
                
                results.append(HybridDetectionResult(
                    line_number=line_info['line_number'],
                    line_text=line_info['line_text'],
                    detected_symbol=line_info['detected_symbol'],
                    symbol_category=line_info['symbol_category'],
                    rule_based_score=0.5,  # è»Ÿè¦å‰‡é€šé
                    bert_score=float(bert_score),
                    final_prediction=final_prediction,
                    method_used=method_used
                ))
        
        elif soft_candidate_lines:
            # æ²’æœ‰ BERT æ¨¡å‹ï¼Œè»Ÿè¦å‰‡å€™é¸å…¨éƒ¨æ¥å—
            if verbose:
                print("âš ï¸ æ²’æœ‰ BERT æ¨¡å‹ï¼Œè»Ÿè¦å‰‡å€™é¸å…¨éƒ¨æ¥å—")
            for i, line_info in soft_line_mapping.items():
                results.append(HybridDetectionResult(
                    line_number=line_info['line_number'],
                    line_text=line_info['line_text'],
                    detected_symbol=line_info['detected_symbol'],
                    symbol_category=line_info['symbol_category'],
                    rule_based_score=0.5,
                    bert_score=0.0,
                    final_prediction=True,  # è»Ÿè¦å‰‡ç‚ºæº–
                    method_used="soft_rule_only"
                ))
        
        # ç¬¬ä¸‰å±¤ï¼šæœ€çµ‚èšåˆ
        if verbose:
            print("ğŸ“Š æ­¥é©Ÿ3: èšåˆæ‰€æœ‰æª¢æ¸¬çµæœ...")
        
        # åˆä½µçµ‚æ¥µåš´æ ¼å’Œè»Ÿè¦å‰‡çµæœ
        all_results = ultra_strict_results + results
        
        # æŒ‰è¡Œè™Ÿæ’åº
        all_results.sort(key=lambda x: x.line_number)
        self.detection_results = all_results
        
        # çµ±è¨ˆçµæœ
        ultra_strict_count = len(ultra_strict_results)
        soft_rule_accepted = sum(1 for r in results if r.final_prediction and r.method_used.startswith("soft_rule"))
        total_detected = ultra_strict_count + soft_rule_accepted
        
        if verbose:
            print(f"âœ… ä¸‰å±¤æª¢æ¸¬å®Œæˆï¼Œè™•ç†äº† {len(text_lines)} è¡Œ")
            print(f"   ğŸ¯ çµ‚æ¥µåš´æ ¼: {ultra_strict_count} å€‹ (100% ç¢ºå®š)")
            print(f"   ğŸ¤– è»Ÿè¦å‰‡+BERT: {soft_rule_accepted} å€‹")
            print(f"   ğŸ“Š ç¸½æª¢æ¸¬: {total_detected} å€‹å±¤ç´šç¬¦è™Ÿ")
        
        return all_results
    
    def detect_hierarchy_levels(self) -> Dict:
        """è‡ªå‹•æª¢æ¸¬å±¤ç´šçµæ§‹ - å¾Œå¾€å‰åˆ†æ
        
        åŸºæ–¼ ultra_strict_detector çš„ç¬¦è™Ÿç¾¤çµ„å±¤ç´šå®šç¾©
        å¾æª”æ¡ˆæœ«å°¾é–‹å§‹æª¢æ¸¬ï¼Œè¿½è¹¤æ–°ç¬¦è™Ÿé¡å‹å‡ºç¾ï¼Œåˆ†é…éå¢å±¤ç´š
        """
        if not self.detection_results:
            return {}
        
        # ç²å–æ‰€æœ‰æ­£é¡çµæœï¼ˆå¯¦éš›æª¢æ¸¬åˆ°çš„å±¤ç´šç¬¦è™Ÿï¼‰
        positive_results = [r for r in self.detection_results if r.final_prediction]
        
        if not positive_results:
            return {'hierarchy_levels': [], 'level_mapping': {}}
        
        # ä¾è¡Œè™Ÿé †åºéæ­·ï¼Œé‡åˆ°æ–°ç¬¦è™Ÿé¡å‹æ™‚å»ºç«‹ä¸‹ä¸€å±¤
        hierarchy_levels = []
        category_levels: Dict[str, int] = {}
        current_level = 1

        for result in positive_results:
            symbol_category = result.symbol_category

            # ç§»é™¤é å®šç¾©å±¤ç´šï¼Œå®Œå…¨å‹•æ…‹å­¸ç¿’
            predefined_level = 0

            if symbol_category not in category_levels:
                category_levels[symbol_category] = current_level
                current_level += 1

            assigned_level = category_levels[symbol_category]

            hierarchy_levels.append({
                'line_number': result.line_number,
                'detected_symbol': result.detected_symbol,
                'symbol_category': symbol_category,
                'predefined_level': predefined_level,
                'assigned_level': assigned_level,
                'is_pua': self.rule_detector.is_pua_character(result.detected_symbol) if result.detected_symbol else False,
                'line_text': result.line_text,
                'method_used': result.method_used,
                'bert_score': result.bert_score
            })

        # å‰µå»ºå±¤ç´šæ˜ å°„è¡¨
        level_mapping = {}
        for item in hierarchy_levels:
            category = item['symbol_category']
            if category not in level_mapping:
                level_mapping[category] = {
                    'assigned_level': item['assigned_level'],
                    'count': 0,
                    'is_pua_category': item['is_pua'],
                    'examples': []
                }
            level_mapping[category]['count'] += 1
            if len(level_mapping[category]['examples']) < 3:
                level_mapping[category]['examples'].append({
                    'line': item['line_number'],
                    'symbol': item['detected_symbol'],
                    'text': item['line_text'][:50] + '...' if len(item['line_text']) > 50 else item['line_text']
                })
        
        return {
            'hierarchy_levels': hierarchy_levels,
            'level_mapping': level_mapping,
            'total_levels': len(category_levels),
            'total_symbols': len(hierarchy_levels)
        }
    
    def analyze_detection_results(self) -> Dict:
        """åˆ†ææª¢æ¸¬çµæœ - åŒ…å«å±¤ç´šçµæ§‹åˆ†æ"""
        if not self.detection_results:
            return {}
        
        total_lines = len(self.detection_results)
        positive_predictions = sum(1 for r in self.detection_results if r.final_prediction)
        
        # æŒ‰æ–¹æ³•çµ±è¨ˆ
        method_stats = {}
        for result in self.detection_results:
            method = result.method_used
            if method not in method_stats:
                method_stats[method] = {'total': 0, 'positive': 0}
            method_stats[method]['total'] += 1
            if result.final_prediction:
                method_stats[method]['positive'] += 1
        
        # ç¬¦è™Ÿé¡åˆ¥çµ±è¨ˆ
        symbol_stats = {}
        for result in self.detection_results:
            if result.final_prediction and result.symbol_category:
                category = result.symbol_category
                if category not in symbol_stats:
                    symbol_stats[category] = 0
                symbol_stats[category] += 1
        
        # BERT ä¿¡å¿ƒåº¦åˆ†æ
        bert_scores = [r.bert_score for r in self.detection_results if r.bert_score > 0 and r.method_used.startswith("soft_rule")]
        
        # PUA çµ‚æ¥µåš´æ ¼çµ±è¨ˆ
        ultra_strict_count = sum(1 for r in self.detection_results if r.method_used == "ultra_strict_pua")
        
        # è‡ªå‹•å±¤ç´šæª¢æ¸¬
        hierarchy_analysis = self.detect_hierarchy_levels()
        
        analysis = {
            'total_lines': total_lines,
            'positive_predictions': positive_predictions,
            'positive_ratio': positive_predictions / total_lines if total_lines > 0 else 0,
            'ultra_strict_count': ultra_strict_count,
            'method_statistics': method_stats,
            'symbol_category_distribution': symbol_stats,
            'hierarchy_analysis': hierarchy_analysis,
            'bert_score_stats': {
                'mean': np.mean(bert_scores) if bert_scores else 0,
                'std': np.std(bert_scores) if bert_scores else 0,
                'min': np.min(bert_scores) if bert_scores else 0,
                'max': np.max(bert_scores) if bert_scores else 0,
                'count': len(bert_scores)
            }
        }
        
        return analysis
    
    def generate_detection_report(self, analysis: Dict) -> str:
        """ç”Ÿæˆæª¢æ¸¬å ±å‘Š - åŒ…å«å±¤ç´šçµæ§‹åˆ†æ"""
        report = f"""
============================================================
ğŸ”¬ ä¸‰å±¤æ··åˆå±¤ç´šç¬¦è™Ÿæª¢æ¸¬å ±å‘Š (å±¤éæ¿¾)
============================================================

ğŸ“Š ç¸½é«”çµ±è¨ˆ:
  è™•ç†è¡Œæ•¸: {analysis['total_lines']:,}
  æª¢æ¸¬åˆ°å±¤ç´šç¬¦è™Ÿ: {analysis['positive_predictions']:,} ({analysis['positive_ratio']:.1%})

ğŸ“ˆ æŒ‰æª¢æ¸¬æ–¹æ³•çµ±è¨ˆ:
"""
        
        for method, stats in analysis['method_statistics'].items():
            positive_rate = stats['positive'] / stats['total'] if stats['total'] > 0 else 0
            method_name = {
                'ultra_strict_pua': 'çµ‚æ¥µåš´æ ¼(PUA+é “è™Ÿ)',
                'soft_rule_bert': 'BERTç²¾ç…‰',
                'soft_rule_only': 'è»Ÿè¦å‰‡æª¢æ¸¬',
                'rule_rejected': 'è¦å‰‡æ‹’çµ•',
                'empty_line': 'ç©ºè¡Œ'
            }.get(method, method)
            report += f"  {method_name:15} : {stats['total']:4} è¡Œ, {stats['positive']:4} æ­£é¡ ({positive_rate:.1%})\n"
        
        if analysis['symbol_category_distribution']:
            report += f"\nğŸ¯ ç¬¦è™Ÿé¡åˆ¥åˆ†å¸ƒ:\n"
            sorted_symbols = sorted(analysis['symbol_category_distribution'].items(), key=lambda x: x[1], reverse=True)
            for category, count in sorted_symbols:
                report += f"  {category:20} : {count:4} å€‹\n"
        
        # å±¤ç´šçµæ§‹åˆ†æå ±å‘Š
        hierarchy = analysis.get('hierarchy_analysis', {})
        if hierarchy and hierarchy.get('hierarchy_levels'):
            report += f"\nğŸ—ï¸ è‡ªå‹•å±¤ç´šçµæ§‹åˆ†æ (å¾Œå¾€å‰æª¢æ¸¬):\n"
            report += f"  æª¢æ¸¬åˆ°å±¤ç´šæ•¸: {hierarchy['total_levels']} å€‹ä¸åŒé¡å‹\n"
            report += f"  å±¤ç´šç¬¦è™Ÿç¸½æ•¸: {hierarchy['total_symbols']} å€‹\n"
            
            # å±¤ç´šæ˜ å°„è¡¨
            if hierarchy.get('level_mapping'):
                report += f"\nğŸ“‹ å±¤ç´šæ˜ å°„è¡¨ (åŸºæ–¼ ultra_strict_detector ç¾¤çµ„):\n"
                sorted_levels = sorted(hierarchy['level_mapping'].items(), 
                                     key=lambda x: x[1]['assigned_level'])
                
                for category, level_info in sorted_levels:
                    assigned_level = level_info['assigned_level']
                    count = level_info['count']
                    is_pua = " [PUA]" if level_info['is_pua_category'] else ""
                    
                    report += f"  Level {assigned_level}: {category:25}{is_pua} ({count} å€‹)\n"
                    
                    # é¡¯ç¤ºä¾‹å­
                    for example in level_info['examples'][:2]:
                        report += f"    â””â”€ è¡Œ{example['line']:4}: {example['symbol']} - {example['text']}\n"
            
            # å±¤ç´šçµæ§‹é è¦½
            report += f"\nğŸ” å±¤ç´šçµæ§‹é è¦½ (å‰15å€‹ç¬¦è™Ÿ):\n"
            for item in hierarchy['hierarchy_levels'][:15]:
                level = item['assigned_level']
                symbol = item['detected_symbol']
                line_num = item['line_number']
                category = item['symbol_category']
                method_icon = "ğŸ¯" if item['method_used'] == "ultra_strict_pua" else "ğŸ¤–"
                pua_mark = "[PUA]" if item['is_pua'] else ""
                bert_info = f" (BERT: {item['bert_score']:.3f})" if item['bert_score'] > 0 and item['bert_score'] < 1.0 else ""
                
                indent = "  " * level
                report += f"{indent}L{level} {method_icon} è¡Œ{line_num:4}: {symbol} {pua_mark}{bert_info} - {item['line_text'][:60]}...\n"
            
            if len(hierarchy['hierarchy_levels']) > 15:
                report += f"  ... é‚„æœ‰ {len(hierarchy['hierarchy_levels']) - 15} å€‹å±¤ç´šç¬¦è™Ÿ\n"
        
        bert_stats = analysis['bert_score_stats']
        if bert_stats['count'] > 0:
            report += f"\nğŸ¤– BERT ä¿¡å¿ƒåº¦çµ±è¨ˆ (è»Ÿè¦å‰‡éƒ¨åˆ†):\n"
            report += f"  è™•ç†è¡Œæ•¸:  {bert_stats['count']}\n"
            report += f"  å¹³å‡ä¿¡å¿ƒåº¦: {bert_stats['mean']:.3f}\n"
            report += f"  æ¨™æº–å·®: {bert_stats['std']:.3f}\n"
            report += f"  ç¯„åœ: {bert_stats['min']:.3f} ~ {bert_stats['max']:.3f}\n"
        
        report += f"\nâš¡ å¯Ÿ:\n"
        if analysis.get('ultra_strict_count', 0) > 0:
            ultra_ratio = analysis['ultra_strict_count'] / analysis['positive_predictions'] if analysis['positive_predictions'] > 0 else 0
            report += f"  çµ‚æ¥µåš´æ ¼æ¯”ä¾‹: {ultra_ratio:.1%} - PUA+é “è™Ÿæ ¼å¼æ¨™æº–åŒ–ç¨‹åº¦\n"
        
        if analysis['positive_ratio'] > 0.5:
            report += f"  é«˜å¯†åº¦æ–‡æª” ({analysis['positive_ratio']:.1%}) - ä¸»è¦ç‚ºå±¤ç´šçµæ§‹\n"
        else:
            report += f"  æ··åˆæ–‡æª” ({analysis['positive_ratio']:.1%}) - åŒ…å«å¤§é‡æ­£æ–‡\n"
        
        if bert_stats['count'] > 0:
            if bert_stats['mean'] > 0.8:
                report += f"  BERTé«˜ä¿¡å¿ƒ ({bert_stats['mean']:.3f}) - æ¸…æ™°çš„é¡åˆ¥é‚Šç•Œ\n"
            elif bert_stats['mean'] > 0.6:
                report += f"  BERTä¸­ç­‰ä¿¡å¿ƒ ({bert_stats['mean']:.3f}) - å­˜åœ¨é‚Šç•Œæƒ…æ³\n"
            else:
                report += f"  BERTä½ä¿¡å¿ƒ ({bert_stats['mean']:.3f}) - éœ€è¦æª¢æŸ¥æ•¸æ“šè³ªé‡\n"
        
        if hierarchy and hierarchy.get('total_levels', 0) > 0:
            report += f"  å±¤ç´šè¤‡é›œåº¦: {hierarchy['total_levels']} å±¤ - æ–‡æª”çµæ§‹åŒ–ç¨‹åº¦æŒ‡æ¨™\n"
        
        report += f"  ä¸‰å±¤éæ¿¾ç­–ç•¥ - å¹³è¡¡äº†æº–ç¢ºæ€§ã€æ•ˆç‡å’Œå¯é æ€§\n"
        
        return report
    
    def save_results(self, output_file: str):
        """ä¿å­˜æª¢æ¸¬çµæœ - åŒ…å« numpy é¡å‹è½‰æ›å’Œå±¤ç´šåˆ†æ"""
        results_data = []
        for result in self.detection_results:
            results_data.append({
                'line_number': result.line_number,
                'line_text': result.line_text,
                'detected_symbol': result.detected_symbol,
                'symbol_category': result.symbol_category,
                'rule_based_score': result.rule_based_score,
                'bert_score': result.bert_score,
                'final_prediction': result.final_prediction,
                'method_used': result.method_used
            })
        
        # ç²å–å±¤ç´šåˆ†æ
        hierarchy_analysis = self.detect_hierarchy_levels()
        
        output_data = {
            'detection_method': 'three_layer_hybrid_with_hierarchy',
            'timestamp': datetime.now().isoformat(),
            'model_path': str(self.model_path) if self.model_path else None,
            'bert_model_loaded': self.is_model_loaded(),
            'total_lines': len(self.detection_results),
            'positive_predictions': sum(1 for r in self.detection_results if r.final_prediction),
            'ultra_strict_count': sum(1 for r in self.detection_results if r.method_used == "ultra_strict_pua"),
            'hierarchy_analysis': hierarchy_analysis,
            'results': results_data
        }
        
        # æ±ºæ–¹æ¡ˆï¼šåºåˆ—åŒ–å‰çµ±ä¸€è½‰æ› numpy é¡å‹
        output_data = convert_numpy_types(output_data)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ æª¢æ¸¬çµæœå·²ä¿å­˜: {output_file}")
        
        # é¡å¤–ä¿å­˜å±¤ç´šçµæ§‹åˆ°ç¨ç«‹æ–‡ä»¶
        if hierarchy_analysis and hierarchy_analysis.get('hierarchy_levels'):
            hierarchy_file = output_file.replace('.json', '_hierarchy.json')
            hierarchy_data = convert_numpy_types(hierarchy_analysis)
            
            with open(hierarchy_file, 'w', encoding='utf-8') as f:
                json.dump(hierarchy_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ—ï¸ å±¤ç´šçµæ§‹å·²ä¿å­˜: {hierarchy_file}")

def main():
    """ä¸»å‡½æ•¸ - æ¼”ç¤ºä¸‰å±¤æ··åˆæª¢æ¸¬å™¨"""
    print("ğŸš€ å•Ÿå‹•ä¸‰å±¤æ··åˆå±¤ç´šç¬¦è™Ÿæª¢æ¸¬å™¨ (æ¨ç†å°ˆç”¨)")
    print("'åˆ†å±¤éæ¿¾' åŸå‰‡ï¼šåš´æ ¼ â†’ è»Ÿè¦å‰‡ â†’ èšåˆ")
    print("="*60)
    
    # åˆå§‹åŒ–æª¢æ¸¬å™¨
    detector = HybridLevelSymbolDetector()
    
    # æª¢æŸ¥æ˜¯å¦æœ‰å·²è¨“ç·´çš„æ¨¡å‹
    model_path = "models/bert/level_detector/best_model"
    if Path(model_path).exists():
        print("ğŸ“¦ è¼‰å…¥å·²è¨“ç·´çš„ BERT æ¨¡å‹...")
        detector.load_bert_model(model_path)
    else:
        print("âš ï¸ æœªæ‰¾åˆ° BERT æ¨¡å‹ï¼Œå°‡åªä½¿ç”¨è¦å‰‡æª¢æ¸¬")
        print(f"ğŸ’¡ è¦è¨“ç·´ BERT æ¨¡å‹ï¼Œè«‹é‹è¡Œ: python train_bert_classifier.py")
    
    # æ¸¬è©¦æª¢æ¸¬
    test_file = "data/sample/TPDM,111,æ˜“,564,20250113,1.json"
    if Path(test_file).exists():
        print(f"\nğŸ§ª æ¸¬è©¦æª¢æ¸¬: {test_file}")
        
        with open(test_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        text_lines = data['JFULL'].split('\n')
        
        # åŸ·è¡Œä¸‰å±¤æ··åˆæª¢æ¸¬
        results = detector.detect_hybrid_markers(text_lines)
        
        # åˆ†æçµæœ
        analysis = detector.analyze_detection_results()
        
        # ç”Ÿæˆå ±å‘Š
        report = detector.generate_detection_report(analysis)
        print(report)
        
        # ä¿å­˜çµæœ
        detector.save_results("three_layer_detection_results.json")
        
        # é¡¯ç¤ºå‰10å€‹æ­£é¡çµæœ
        positive_results = [r for r in results if r.final_prediction][:10]
        if positive_results:
            print(f"\nğŸ“‹ æª¢æ¸¬åˆ°çš„å±¤ç´šç¬¦è™Ÿ (å‰10å€‹):")
            for i, result in enumerate(positive_results, 1):
                method_icon = "ğŸ¯" if result.method_used == "ultra_strict_pua" else "ğŸ¤–"
                confidence_info = f" (BERT: {result.bert_score:.3f})" if result.bert_score > 0 and result.bert_score < 1.0 else ""
                print(f"  {i:2}. {method_icon} è¡Œ {result.line_number:3}: {result.detected_symbol}{confidence_info} - {result.line_text[:80]}...")
    
    else:
        print(f"âŒ æ¸¬è©¦æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")

if __name__ == "__main__":
    main()
