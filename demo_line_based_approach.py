#!/usr/bin/env python3
"""
åŸºæ–¼è¡Œçš„è‡ªé©æ‡‰å±¤ç´šæª¢æ¸¬æ¼”ç¤º
å±•ç¤ºå®Œæ•´çš„ line-based approach æµç¨‹ï¼š

1. æª¢æ¸¬ç‰¹æ®Šæ¨™è¨˜ï¼šä¸»æ–‡(lv 0)ã€ç†ç”±(lv 0)ã€äº‹å¯¦(lv 0)ã€äº‹å¯¦åŠç†ç”±(lv 0)ã€æ—¥æœŸ(lv -2)
2. Header/Footer å€åŸŸï¼šä¸»æ–‡ä¹‹å‰(lv -3)ã€æœ€å¾Œæ—¥æœŸä¹‹å¾Œ(lv -3)  
3. å…§å®¹å€åŸŸï¼šå…©å€‹å±¤ç´šç¬¦è™Ÿè¡Œä¹‹é–“(lv -1)
4. å±¤ç´šç¬¦è™Ÿæª¢æ¸¬ï¼šåŸºæ–¼ R-D æˆ– S-D å­¸ç¿’çš„è¦å‰‡(lv 1,2,3,4...)
5. ç›¸åŒå±¤ç´šå…§å®¹åˆä½µï¼šå°‡æ‰€æœ‰ Lv -1 å…§å®¹åˆä½µç­‰
"""

import sys
import json
from pathlib import Path

# æ·»åŠ  src è·¯å¾‘
sys.path.append('src')

from lchunk.detectors.adaptive_hybrid import IntelligentHybridDetector

def demonstrate_line_based_approach():
    """æ¼”ç¤ºåŸºæ–¼è¡Œçš„åˆ†å¡Šæ–¹æ³•"""
    print("ğŸš€ åŸºæ–¼è¡Œçš„è‡ªé©æ‡‰å±¤ç´šæª¢æ¸¬æ¼”ç¤º")
    print("="*80)
    print("æµç¨‹: æª¢æ¸¬ç‰¹æ®Šæ¨™è¨˜ â†’ å­¸ç¿’å±¤ç´šè¦å‰‡ â†’ åŸºæ–¼è¡Œåˆ†å¡Š â†’ å…§å®¹åˆä½µ")
    print()
    
    # åˆå§‹åŒ–æª¢æ¸¬å™¨
    model_path = "models/bert/level_detector/best_model"
    detector = IntelligentHybridDetector(model_path if Path(model_path).exists() else None)
    
    # é¸æ“‡æ¸¬è©¦æª”æ¡ˆ
    sample_dir = Path("data/samples")
    test_files = list(sample_dir.glob("*.json"))
    
    if not test_files:
        print("âŒ æ²’æœ‰æ‰¾åˆ°æ¸¬è©¦æª”æ¡ˆ")
        return
    
    test_file = test_files[0]
    print(f"ğŸ“ è™•ç†æª”æ¡ˆ: {test_file.name}")
    
    # åŸ·è¡Œå®Œæ•´è™•ç†æµç¨‹
    result = detector.process_single_file(test_file)
    
    if not result:
        print("âŒ è™•ç†å¤±æ•—")
        return
    
    print(f"\nâœ… è™•ç†å®Œæˆï¼")
    
    # === æ­¥é©Ÿ1: ç‰¹æ®Šæ¨™è¨˜æª¢æ¸¬çµæœ ===
    print(f"\nğŸ“ æ­¥é©Ÿ1: ç‰¹æ®Šæ¨™è¨˜æª¢æ¸¬")
    with open(test_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    lines = data['JFULL'].split('\n')
    special_markers = detector.detect_special_markers(lines)
    
    for marker_type, line_numbers in special_markers.items():
        if line_numbers:
            print(f"  âœ“ {marker_type}: ç¬¬ {[n+1 for n in line_numbers]} è¡Œ")
        else:
            print(f"  âœ— {marker_type}: æœªæª¢æ¸¬åˆ°")
    
    # === æ­¥é©Ÿ2: å­¸ç¿’å±¤ç´šè¦å‰‡ ===
    print(f"\nğŸ“ æ­¥é©Ÿ2: å¾ {result.learning_region} å­¸ç¿’å±¤ç´šè¦å‰‡")
    for rule in result.learned_rules:
        print(f"  ğŸ“‹ {rule.symbol_category}: Level {rule.assigned_level} (ä¿¡å¿ƒåº¦: {rule.confidence:.3f})")
    
    # === æ­¥é©Ÿ3: åŸºæ–¼è¡Œçš„åˆ†å¡Šçµ±è¨ˆ ===
    print(f"\nğŸ—ï¸ æ­¥é©Ÿ3: åŸºæ–¼è¡Œåˆ†å¡Šçµæœ")
    if result.line_based_chunks:
        level_stats = {}
        for chunk in result.line_based_chunks:
            level = chunk.level
            chunk_type = chunk.chunk_type
            key = f"Lv{level}_{chunk_type}"
            level_stats[key] = level_stats.get(key, 0) + 1
        
        for key, count in sorted(level_stats.items()):
            print(f"  ğŸ“¦ {key}: {count} å€‹åˆ†å¡Š")
    
    # === æ­¥é©Ÿ4: å±¤ç´šå…§å®¹åˆä½µ ===
    print(f"\nğŸ”— æ­¥é©Ÿ4: å±¤ç´šå…§å®¹åˆä½µçµ±è¨ˆ")
    stats = result.processing_stats
    if 'level_content_summary' in stats:
        for level, line_count in sorted(stats['level_content_summary'].items()):
            print(f"  ğŸ“„ {level}: {line_count} è¡Œå…§å®¹")
    
    # === æ­¥é©Ÿ5: åˆ†å¡Šç¤ºä¾‹ ===
    print(f"\nğŸ“‹ æ­¥é©Ÿ5: å„å±¤ç´šåˆ†å¡Šç¤ºä¾‹")
    
    if result.line_based_chunks:
        # æŒ‰å±¤ç´šåˆ†çµ„
        level_groups = {}
        for chunk in result.line_based_chunks:
            level = chunk.level
            if level not in level_groups:
                level_groups[level] = []
            level_groups[level].append(chunk)
        
        # é¡¯ç¤ºæ¯å€‹å±¤ç´šçš„ä»£è¡¨æ€§ç¤ºä¾‹
        for level in sorted(level_groups.keys()):
            chunks = level_groups[level]
            print(f"\n  ğŸ¯ Level {level} ç¤ºä¾‹:")
            
            # æ ¹æ“šå±¤ç´šé¡å‹é¸æ“‡é¡¯ç¤ºé‚è¼¯
            if level == -3:
                print(f"    Header/Footer å€åŸŸ: {len(chunks)} å€‹åˆ†å¡Š")
                if chunks:
                    for chunk in chunks[:2]:
                        content_preview = chunk.content_lines[0][:50] + "..." if chunk.content_lines else ""
                        print(f"    ğŸ“ {chunk.chunk_type}: è¡Œ{chunk.start_line+1}-{chunk.end_line+1}")
                        print(f"       {content_preview}")
            
            elif level == -2:
                print(f"    æ—¥æœŸæ¨™è¨˜: {len(chunks)} å€‹")
                for chunk in chunks:
                    content = chunk.content_lines[0] if chunk.content_lines else ""
                    print(f"    ğŸ“… è¡Œ{chunk.start_line+1}: {content.strip()}")
            
            elif level == -1:
                print(f"    å…§å®¹å€åŸŸ: {len(chunks)} å€‹åˆ†å¡Š")
                for chunk in chunks[:3]:  # åªé¡¯ç¤ºå‰3å€‹
                    content_preview = chunk.content_lines[0][:40] + "..." if chunk.content_lines else ""
                    print(f"    ğŸ“„ è¡Œ{chunk.start_line+1}-{chunk.end_line+1}: {content_preview}")
                if len(chunks) > 3:
                    print(f"    ... é‚„æœ‰ {len(chunks) - 3} å€‹å…§å®¹åˆ†å¡Š")
            
            elif level == 0:
                print(f"    ç‰¹æ®Šæ¨™è¨˜: {len(chunks)} å€‹")
                for chunk in chunks:
                    content = chunk.content_lines[0] if chunk.content_lines else ""
                    print(f"    ğŸ·ï¸ {chunk.chunk_type}: {content.strip()}")
            
            else:  # level >= 1
                print(f"    å±¤ç´šç¬¦è™Ÿ: {len(chunks)} å€‹")
                for chunk in chunks[:3]:  # åªé¡¯ç¤ºå‰3å€‹
                    symbol = chunk.leveling_symbol or ""
                    content = chunk.content_lines[0] if chunk.content_lines else ""
                    content_preview = content[:50] + "..." if len(content) > 50 else content
                    print(f"    ğŸ“Œ [{symbol}] è¡Œ{chunk.start_line+1}: {content_preview}")
                if len(chunks) > 3:
                    print(f"    ... é‚„æœ‰ {len(chunks) - 3} å€‹å±¤ç´šç¬¦è™Ÿ")
    
    print(f"\nâœ… åŸºæ–¼è¡Œçš„è‡ªé©æ‡‰å±¤ç´šæª¢æ¸¬æ¼”ç¤ºå®Œæˆï¼")
    print(f"   ç¸½å…±è™•ç†äº† {stats['total_lines']} è¡Œ")
    print(f"   ç”Ÿæˆäº† {stats.get('line_based_chunks_count', 0)} å€‹åˆ†å¡Š")
    print(f"   è¦†è“‹äº† {len(stats.get('level_content_summary', {}))} å€‹å±¤ç´š")

if __name__ == "__main__":
    demonstrate_line_based_approach()