# 模型比較評估報告

**評估時間**: 2025-10-13 15:58:12

## 模型性能總覽

| 模型 | 準確率 | 精確率 | 召回率 | F1分數 | AUC |
|------|--------|--------|--------|--------|----- |
| BERT | 0.9905 | 0.9895 | 1.0000 | 0.9947 | 0.9945 |
| Random Forest | 0.9052 | 0.9043 | 1.0000 | 0.9497 | 0.6705 |
| Logistic Regression | 0.9005 | 0.9038 | 0.9947 | 0.9471 | 0.7210 |
| SVM | 0.4550 | 1.0000 | 0.3915 | 0.5627 | 0.6931 |

## 🏆 最佳模型: BERT

### 最佳模型性能:
- **準確率**: 0.9905
- **精確率**: 0.9895
- **召回率**: 1.0000
- **F1分數**: 0.9947
- **AUC**: 0.9945

## 模型分析

### 傳統機器學習 vs BERT
- **BERT 模型表現最佳**，深度學習在文本分類任務上的優勢明顯

### 建議
- 生產環境推薦使用最佳模型進行層級符號檢測
- 考慮模型複雜度與性能的平衡
- 定期重新評估和更新模型
