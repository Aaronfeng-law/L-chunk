#!/usr/bin/env python3
"""
æ¸¬è©¦åŸºæ–¼è¡Œçš„è‡ªé©æ‡‰å±¤ç´šæª¢æ¸¬å™¨
"""

import sys
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
sys.path.append('.')
sys.path.append('src')

from src.lchunk.detectors.adaptive_hybrid import IntelligentHybridDetector

def test_line_based_detection():
    """æ¸¬è©¦åŸºæ–¼è¡Œçš„æª¢æ¸¬"""
    print("ğŸ§ª æ¸¬è©¦åŸºæ–¼è¡Œçš„è‡ªé©æ‡‰å±¤ç´šæª¢æ¸¬")
    print("="*60)
    
    # åˆå§‹åŒ–æª¢æ¸¬å™¨ (ä¸éœ€è¦BERTæ¨¡å‹ä¹Ÿèƒ½å·¥ä½œ)
    detector = IntelligentHybridDetector()
    
    # æ¸¬è©¦æ¨£æœ¬æª”æ¡ˆ
    sample_dir = Path("data/samples")
    if not sample_dir.exists():
        # å›é€€åˆ° filtered ç›®éŒ„
        sample_dir = Path("data/processed/filtered")
    
    if not sample_dir.exists():
        print("âŒ æ‰¾ä¸åˆ°æ¸¬è©¦æ•¸æ“šç›®éŒ„")
        return
    
    # æ‰¾åˆ°ç¬¬ä¸€å€‹JSONæª”æ¡ˆé€²è¡Œæ¸¬è©¦
    json_files = list(sample_dir.glob("*.json"))
    if not json_files:
        print("âŒ æ‰¾ä¸åˆ°JSONæ¸¬è©¦æª”æ¡ˆ")
        return
    
    test_file = json_files[0]
    print(f"ğŸ“„ æ¸¬è©¦æª”æ¡ˆ: {test_file.name}")
    
    # åŸ·è¡ŒåŸºæ–¼è¡Œçš„æª¢æ¸¬
    result = detector.process_single_file(test_file)
    
    if result:
        print(f"\nâœ… æª¢æ¸¬æˆåŠŸ!")
        print(f"   æª”æ¡ˆ: {result.filename}")
        print(f"   å­¸ç¿’æ¨¡å¼: {result.learning_region}")
        print(f"   è™•ç†çµ±è¨ˆ:")
        
        stats = result.processing_stats
        for key, value in stats.items():
            print(f"     {key}: {value}")
        
        # é¡¯ç¤ºåŸºæ–¼è¡Œçš„åˆ†å¡Šçµæœ
        if 'line_based_chunks' in result.applied_hierarchy:
            chunks = result.applied_hierarchy['line_based_chunks']
            print(f"\nğŸ“‹ åŸºæ–¼è¡Œçš„åˆ†å¡Šçµæœ:")
            
            for level in sorted(chunks.keys()):
                chunk_count = len(chunks[level])
                level_name = {
                    -3: "Header/Footer", 
                    -2: "æ—¥æœŸ", 
                    -1: "å…§å®¹", 
                    0: "ç‰¹æ®Šæ¨™è¨˜"
                }.get(level, f"å±¤ç´šç¬¦è™Ÿ")
                
                print(f"   L{level} ({level_name}): {chunk_count} å€‹åˆ†å¡Š")
                
                # é¡¯ç¤ºå‰2å€‹åˆ†å¡Šçš„è©³ç´°å…§å®¹
                for i, chunk in enumerate(chunks[level][:2]):
                    print(f"     åˆ†å¡Š {i+1}:")
                    
                    if 'symbol_lines' in chunk and chunk['symbol_lines']:
                        print(f"       ç¬¦è™Ÿè¡Œ: {len(chunk['symbol_lines'])} è¡Œ")
                        for sym_line in chunk['symbol_lines'][:2]:
                            print(f"         è¡Œ{sym_line['line_number']:4}: {sym_line['line_text'][:50]}...")
                    
                    if 'content_lines' in chunk and chunk['content_lines']:
                        print(f"       å…§å®¹è¡Œ: {len(chunk['content_lines'])} è¡Œ")
                        for content_line in chunk['content_lines'][:2]:
                            print(f"         è¡Œ{content_line['line_number']:4}: {content_line['line_text'][:50]}...")
                    
                    if 'lines' in chunk and chunk['lines']:
                        print(f"       ç¸½è¡Œæ•¸: {len(chunk['lines'])} è¡Œ")
                        for line_item in chunk['lines'][:2]:
                            print(f"         è¡Œ{line_item['line_number']:4}: {line_item['line_text'][:50]}...")
        
        print(f"\nğŸ¯ æ¸¬è©¦å®Œæˆ!")
    else:
        print("âŒ æª¢æ¸¬å¤±æ•—")

def test_special_markers():
    """æ¸¬è©¦ç‰¹æ®Šæ¨™è¨˜æª¢æ¸¬"""
    print("\nğŸ” æ¸¬è©¦ç‰¹æ®Šæ¨™è¨˜æª¢æ¸¬")
    print("-"*40)
    
    # å‰µå»ºæ¸¬è©¦è¡Œ
    test_lines = [
        "é€™æ˜¯æ¨™é¡Œè¡Œ",
        "ä¸»æ–‡",
        "ä¸€ã€ç¬¬ä¸€å±¤",
        "(ä¸€)ç¬¬äºŒå±¤",
        "é€™æ˜¯å…§å®¹è¡Œ1",
        "é€™æ˜¯å…§å®¹è¡Œ2", 
        "äº‹å¯¦",
        "äºŒã€äº‹å¯¦å…§å®¹",
        "ç†ç”±",
        "ä¸‰ã€ç†ç”±å…§å®¹",
        "äº‹å¯¦åŠç†ç”±",
        "å››ã€åˆä½µå…§å®¹",
        "ä¸­è¯æ°‘åœ‹113å¹´10æœˆ14æ—¥",
        "é€™æ˜¯æœ€å¾Œä¸€è¡Œ"
    ]
    
    detector = IntelligentHybridDetector()
    
    # æª¢æ¸¬ç‰¹æ®Šæ¨™è¨˜
    special_markers = detector.detect_special_markers(test_lines)
    
    print("æª¢æ¸¬åˆ°çš„ç‰¹æ®Šæ¨™è¨˜:")
    for marker_type, markers in special_markers.items():
        if markers:
            print(f"  {marker_type}:")
            for line_num, line_text in markers:
                print(f"    è¡Œ{line_num:2}: {line_text}")
    
    # æ¸¬è©¦åŸºæ–¼è¡Œçš„å±¤ç´šåˆ†æ
    line_hierarchy = detector.create_line_based_hierarchy(test_lines)
    
    print(f"\nè¡Œç´šåˆ¥æ˜ å°„:")
    line_levels = line_hierarchy['line_levels']
    for line_num in sorted(line_levels.keys()):
        level = line_levels[line_num]
        line_text = test_lines[line_num] if line_num < len(test_lines) else ""
        level_name = {
            -3: "Header/Footer", 
            -2: "æ—¥æœŸ", 
            -1: "å…§å®¹", 
            0: "ç‰¹æ®Šæ¨™è¨˜", 
            None: "å¾…åˆ†é…"
        }.get(level, f"L{level}")
        
        print(f"  è¡Œ{line_num:2} (L{level if level is not None else '?'} {level_name}): {line_text}")

if __name__ == "__main__":
    test_special_markers()
    test_line_based_detection()